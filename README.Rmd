---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
options(tibble.print_min = 5)
options(tibble.print_max = 10)
set.seed(949958487)
```

# fastplyr

<!-- badges: start -->

[![R-CMD-check](https://github.com/NicChr/fastplyr/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/NicChr/fastplyr/actions/workflows/R-CMD-check.yaml)

<!-- badges: end -->

fastplyr aims to provide a [tidyverse](https://www.tidyverse.org/learn) frontend using a [collapse](https://sebkrantz.github.io/collapse/articles/collapse_intro.html) backend. This means from a user's point of view the functions behave like the tidyverse equivalents and thus require little to no changes to existing code to convert. 

fastplyr is designed to handle operations that involve larger numbers of groups and generally larger data.

## Installation

You can install the development version of fastplyr from [GitHub](https://github.com/) with:

``` r
# install.packages("pak")
pak::pak("NicChr/fastplyr")
```

Load packages

```{r example}
library(tidyverse)
library(fastplyr)
library(nycflights13)
library(bench)
```

While the syntax and user-interface of fastplyr aligns very closely with dplyr most of the time, there can be a few key differences.

## Differences between fastplyr and dplyr

+--------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+
|                          | ### dplyr                                                                                                        | ### fastplyr                                                                                                              |
+==========================+==================================================================================================================+===========================================================================================================================+
| `.by`                    | Groups are sorted by order of first appearance always when using `.by`                                           | Groups are always sorted by default, even when using `.by`. One can use the other sorting through `f_group_by(order = F)` |
+--------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+
| Many groups              | Generally slow for data with many groups.                                                                        | Designed to be fast for data with many groups.                                                                            |
+--------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+
| Handling of dots (`...`) | dplyr almost always executes `...` expressions in a way that latter expressions depend on previous ones          | Some functions like `f_summarise` and `f_expand` execute the expressions in `...` independently.                          |
+--------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+
| Duplicate rows           | No dedicated function for this, solution using `group_by |> filter(n() > 1)` are generally slow for larger data. | Dedicated function `f_duplicates` can do this very fast and with fine control.                                            |
+--------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+
| Unique group IDs         | Achieved through `mutate(cur_group_id())`                                                                        | Dedicated fast function `add_group_id()`                                                                                  |
+--------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+
| Row slicing              | `slice()` supports data-masked expressions supplied to `...`                                                     | Data-masked expressions not supported in `f_slice_` functions. Use `f_filter()` for this behaviour.                       |
+--------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+
| Memory usage             | High memory usage                                                                                                | Lower usage compared to dplyr                                                                                             |
+--------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+
| joins                    | Accepts different types of joins, e.g. rolling and equality joins.                                               | Accepts only equality joins of the form `x == y`                                                                          |
+--------------------------+------------------------------------------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------------------------------+

## dplyr alternatives

All tidyverse alternative functions are prefixed with 'f\_'. For example, `dplyr::distinct` becomes `fastplyr::f_distinct`.

### distinct

```{r}
flights |> 
  f_distinct(origin, dest)
```

`f_distinct` has an additional `sort` argument which is much faster than sorting afterwards.

```{r}
mark(
  fastplyr_distinct_sort = flights |> 
  f_distinct(origin, dest, tailnum, sort = TRUE),
  dplyr_distinct_sort = flights |> 
    distinct(origin, dest, tailnum) |> 
    arrange_all()
)
```

### group_by

`f_group_by` operates very similarly with an additional feature that allows you to specify whether group data should be ordered or not. This ultimately controls if the groups end up sorted in expressions like `count` and `summarise`, but also in this case `f_count` and `f_summarise`.

```{r}
# Like dplyr
flights |> 
  f_group_by(month) |> 
  f_count()

# Group data is sorted by order-of-first appearance
flights |> 
  f_group_by(month, order = FALSE) |> 
  f_count()
```

Just a reminder that all fastplyr functions are interchangeable with dplyr ones both ways

```{r}

### With dplyr::count

flights |> 
  f_group_by(month) |> 
  count()
```

```{r}

### With dplyr::group_by

flights |> 
  group_by(month) |> 
  f_count()
```

### summarise

`f_summarise` behaves like dplyr's `summarise` except for two things:

-   It evaluates expressions independently
-   There are optimisations for common statistical functions which are very fast for many groups

```{r}
grouped_flights <- flights |> 
  group_by(across(where(is.character)))

grouped_flights |> 
  f_summarise(
    n = n(), mean_dep_delay = mean(dep_delay)
  )
```

And a benchmark

```{r}
mark(
  fastplyr_summarise = grouped_flights |> 
  f_summarise(
    n = n(), mean_dep_delay = mean(dep_delay)
  ),
  dplyr_summarise = grouped_flights |> 
  summarise(
    n = n(), mean_dep_delay = mean(dep_delay, na.rm = TRUE),
    .groups = "drop"
  )
)
```

### Joins

Joins work much the same way as in dplyr.

```{r}
left <- flights |> 
  f_select(origin, dest, time_hour)
hours <- sample(unique(left$time_hour), 5000)
right <- as.data.frame(unclass(as.POSIXlt(hours)))
right$time_hour <- hours

# Left join

left |> 
  f_left_join(right)

# inner join

left |> 
  f_inner_join(right)

# Anti join

left |> 
  f_anti_join(right)

# Semi join

left |> 
  f_semi_join(right)

# full join

left |> 
  f_full_join(right)
```

And a benchmark comparing fastplyr and dplyr joins

```{r}
mark(
  fastplyr_left_join = f_left_join(left, right, by = "time_hour"),
  dplyr_left_join = left_join(left, right, by = "time_hour")
)
```

```{r}
mark(
  fastplyr_inner_join = f_inner_join(left, right, by = "time_hour"),
  dplyr_inner_join = inner_join(left, right, by = "time_hour")
)
```

```{r}
mark(
  fastplyr_anti_join = f_anti_join(left, right, by = "time_hour"),
  dplyr_anti_join = anti_join(left, right, by = "time_hour")
)
```

```{r}
mark(
  fastplyr_semi_join = f_semi_join(left, right, by = "time_hour"),
  dplyr_semi_join = semi_join(left, right, by = "time_hour")
)
```

```{r}
mark(
  fastplyr_full_join = f_full_join(left, right, by = "time_hour"),
  dplyr_full_join = full_join(left, right, by = "time_hour")
)
```


### slice

`f_slice` and other `f_slice_` functions are very fast for many groups.

```{r}
grouped_flights |> 
  f_slice(1)

grouped_flights |>
  f_slice_head(3)
```

A quick benchmark to prove the point

```{r}
mark(
    fastplyr_slice = grouped_flights |> 
    f_slice_head(n = 3),
    dplyr_slice = grouped_flights |>
        slice_head(n = 3)
)
```

### Group IDs

In dplyr to work with group IDs you must use the `mutate()` + `cur_group_id()` paradigm.

In fastplyr you can just use `add_group_id()` which is blazing fast.

```{r}

## Unique ID for each group

grouped_flights |> 
  add_group_id() |> 
  f_select(group_id)

```

Another benchmark

```{r}
mark(
  fastplyr_group_id = grouped_flights |> 
  add_group_id() |> 
  f_select(all_of(group_vars(grouped_flights)), group_id),
  dplyr_group_id = grouped_flights |> 
  mutate(group_id = cur_group_id()) |> 
  select(all_of(group_vars(grouped_flights)), group_id)
)
```

### expand

Based closely on `tidyr::expand`, `f_expand()` can cross joins multiple vectors and data frames.

```{r}
mark(
    fastplyr_expand = flights |> 
        f_group_by(origin, tailnum) |> 
        f_expand(month = 1:12),
    tidyr_expand = flights |> 
        group_by(origin, tailnum) |> 
        expand(month = 1:12),
    check = FALSE
)


# Using `.cols` in `f_expand()` is very fast!
mark(
    fastplyr_expand = flights |> 
        f_group_by(origin, dest) |> 
        f_expand(.cols = c("year", "month", "day")),
    tidyr_expand = flights |> 
        group_by(origin, dest) |> 
        expand(year, month, day),
    check = FALSE
)
```

### duplicate rows

Finding duplicate rows is a very common dataset operation and there is a dedicated function `f_duplicates()` to do exactly this.

```{r}
flights |> 
  f_duplicates(time_hour)
```

Benchmark against a common dplyr strategy for finding duplicates

```{r}
mark(
 fastplyr_duplicates = flights |> 
   f_duplicates(time_hour, .both_ways = TRUE, .add_count = TRUE, .keep_all = TRUE),
 dplyr_duplicates = flights |> 
   add_count(time_hour) |> 
   filter(n > 1)
)
```

### filter

In the worst-case scenarios, `f_filter()` is about the same speed as `filter()` and in the best-case is much faster and more efficient. This is especially true for large data where small subsets of the data are returned.

```{r}
full <- new_tbl(x = rnorm(5e07))

# A worst case scenario

mark(
  fastplyr_filter = full |> 
    f_filter(abs(x) > 0),
  dplyr_filter = full |> 
    filter(abs(x) > 0)
)

# Best case scenario - filter results in small subset

mark(
  fastplyr_filter = full |> 
    f_filter(x > 4),
  dplyr_filter = full |> 
    filter(x > 4)
)
```

### bind rows and cols

Binding columns is particular much faster but binding rows is also sufficiently faster

```{r}
mark(
  fastplyr_bind_cols = f_bind_cols(grouped_flights, grouped_flights),
  dplyr_bind_cols = suppressMessages(
    bind_cols(grouped_flights, grouped_flights)
    )
)

mark(
  fastplyr_bind_rows = f_bind_rows(grouped_flights, grouped_flights),
  dplyr_bind_rows = bind_rows(grouped_flights, grouped_flights)
)
```


### Quantiles

A typical tidy approach might use a mixture of `reframe()` and `enframe()`
which is a perfectly tidy and neat solution

```{r}
probs <- seq(0, 1, 0.25)

mtcars <- as_tbl(mtcars)

mtcars |> 
 group_by(cyl) |> 
 reframe(enframe(quantile(mpg, probs), "quantile", "mpg"))
```

fastplyr though has a dedicated function for quantile calculation, 
`tidy_quantiles()` which requires less code to type

```{r}

# Wide
mtcars |> 
  tidy_quantiles(mpg, .by = cyl)

# Long
mtcars |> 
  tidy_quantiles(mpg, .by = cyl, pivot = "long")
```

Not only can you choose how to pivot as shown above, you can also calculate
quantiles for multiple variables.

```{r}
multiple_quantiles <- mtcars |> 
  tidy_quantiles(across(where(is.numeric)), pivot = "long")
multiple_quantiles

# Quantile names is a convenient factor
multiple_quantiles$.quantile
```

### Quantile benchmark for many groups

`tidy_quantiles()` of course is fast when many groups are involved.

```{r}
mark(
  fastplyr_quantiles = flights |> 
    f_group_by(year, month, day, origin) |> 
  tidy_quantiles(dep_delay, pivot = "long"),
  dplyr_quantiles = flights |> 
     group_by(year, month, day, origin) |> 
    reframe(enframe(quantile(dep_delay, seq(0, 1, 0.25), na.rm = TRUE))),
  check = FALSE
)
```



## tidytable vs fastplyr

Let's run some more benchmarks for fun, this time including tidytable which fastplyr is very similar to as it also uses a tidy frontend but a data.table backend

### 10 million rows

```{r}
n_rows <- 10^7
n_groups <- 10^6

tbl <- new_tbl(x = rnorm(n_rows))
tbl <- tbl |> 
    mutate(y = as.character(round(x, 6)),
           g = sample.int(n_groups, n_rows, TRUE))
tbl
```

### slice benchmark

For this we will be using the `.by` argument from each package. Because fastplyr still sorts the groups by default here we will set an internal option to use the alternative grouping algorithm that sorts groups by order of first appearance. This will likely be revisited at some point.

To read about the differences, see `?collapse::GRP`.

```{r}
library(tidytable)

tidy_tbl <- as_tidytable(tbl)

# Setting an internal option to set all grouping to use the non-sorted type
options(.fastplyr.order.groups = FALSE)

mark(
  fastplyr_slice = tbl |> 
  f_slice(3:5, .by = g),
  tidytable_slice = tidy_tbl |> 
    slice(3:5, .by = g),
  check = FALSE,
  min_iterations = 3
)
```

### slice_head & slice_tail

```{r}
mark(
  fastplyr_slice_head = tbl |> 
  f_slice_head(n = 3, .by = g),
  tidytable_slice_head = tidy_tbl |> 
    slice_head(n = 3, .by = g),
  fastplyr_slice_tail = tbl |> 
  f_slice_tail(n = 3, .by = g),
  tidytable_slice_tail = tidy_tbl |> 
    slice_tail(n = 3, .by = g),
  check = FALSE,
  min_iterations = 3
)
```

### summarise benchmark

Here we'll calculate the mean of x by each group of g

Both tidytable and fastplyr have optimisations for `mean()` when it involves groups. tidytable internally uses data.table's 'gforce' mean function. This is basically a dedicated C function to calculate means for many groups.

```{r}
mark(
  fastplyr_sumarise = tbl |> 
  f_summarise(mean = mean(x), .by = g),
  tidytable_sumarise = tidy_tbl |> 
  summarise(mean = mean(x), .by = g),
  check = FALSE,
  min_iterations = 3
)
```

Benchmarking more statistical functions

```{r}
mark(
  fastplyr_sumarise2 = tbl |> 
  f_summarise(n = n(), mean = mean(x), min = min(x), max = max(x), .by = g),
  tidytable_sumarise2 = tidy_tbl |> 
  summarise(n = n(), mean = mean(x), min = min(x), max = max(x), .by = g),
  check = FALSE,
  min_iterations = 3
)
```

### count benchmark

```{r}
mark(
  fastplyr_count = tbl |> 
    f_count(y, g),
  tidytable_count = tidy_tbl |> 
    count(y, g),
  check = FALSE,
  min_iterations = 3
)
```

It's clear both fastplyr and tidytable are fast and each have their strengths and weaknesses.
